{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "This assignment has two main parts:\n",
    "\n",
    "    1. **PCA** : In this part the goal is to implement the dimensionality reduction technique *Principal Component Analysis (PCA)* to a very high dimensional data and apply visualization. Note that you are not allowed to use the built-in PCA API provided by the sklearn library. Instead you will be implementing from the scratch. Use the data in data/train.csv for generating the PCA. See the detailed intructions below.\n",
    "    \n",
    "    2. **Recommendation system** : In this part use SVD to get USVT decomposition on the data in train.csv to recommend the movies to the users in test.csv. The submissions.csv should contain user_id (from the test.csv) followed by recommended ratings for all movies.\n",
    "\n",
    "   For this task we use the  MovieLens dataset. The data is in train.csv.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import sqrtm\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-1a: Convert data to user-movie rating matrix\n",
    "    - Read the train.csv file and movies.dat file and use user_id and movie_id to create user-movie rating matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMovieRatingData():\n",
    "    # TODO Read the user-movie rating in data/train.csv and convert it to a user-movie rating matrix (users in the rows and movies in the colums)\n",
    "    # Mind the header row in the train.csv\n",
    "    ratingdata = pd.read_csv('data/train.csv')\n",
    "    ratingdata_matrix = ratingdata.pivot(index = 'user_id', columns = 'movie_id', values = 'rating').fillna(0)    \n",
    "    return ratingdata_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMovieDeata():\n",
    "    # Read the movie data from data/movies.dat\n",
    "    movie_data = pd.io.parsers.read_csv('data/movies.dat', names=['movie_id', 'title', 'genre'], engine='python', delimiter='::')\n",
    "    movie_data_file = pd.io.parsers.read_csv('data/movies.dat', names=['movie_id', 'title', 'genre'], engine='python', delimiter='::')\n",
    "    for i in range(len(movie_data['genre'])):\n",
    "        movie_data_file['genre'][i] = movie_data_file['genre'][i].split('|',1)[0]\n",
    "    return movie_data, movie_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to compute PCA for movies so transpose the matrix using X=readMovieRatingData().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-1b: Preprocessing\n",
    "Before implementing PCA you are required to perform some preprocessing steps:\n",
    "1. Mean normalization: Replace each feature/attribute, $x_{ji}$ with $x_j - \\mu_j$, In other words, determine the mean of each feature set, and then for each feature subtract the mean from the value, so we re-scale the mean to be 0 \n",
    "2. Feature scaling: If features have very different scales then scale make them comparable by altering the scale, so they all have a comparable range of values e.g. $x_{ji}$ is set to $(x_j - \\mu_j) / s_j$  Where $s_j$ is some measure of the range, so could be  $\\max(x_j) - \\min(x_j)$ or Standard deviation $stddev(x_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO We can see features have very different scales. So we apply feature scaling with Standard \n",
    "# deviation as measure of the range, using StandardScaler from scikit-learn\n",
    "def preprocessing_standardization(X):\n",
    "    X_normalized = preprocessing.normalize(X)\n",
    "    standardisation = preprocessing.StandardScaler() \n",
    "    X_standardised = standardisation.fit_transform(X_normalized)\n",
    "    return X_standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-2: Covariance matrix\n",
    "Now the preprocessing is finished. Next, as explained in the lecture, you need to compute the covariance matrix https://en.wikipedia.org/wiki/Covariance_matrix. Given $n \\times m$ $n$ rows and $m$ columns matrix, a covariance matrix is an $n \\times n$ matrix given as below (sigma)\n",
    "$\\Sigma = \\frac{1}{m}\\sum{\\left(x^{i}\\right)\\times \\left(x^{i}\\right)^{T}}$\n",
    "You may use the \"numpy.cov\" function in numpy library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions for part 3, 4, and 5\n",
    "- getSVD() function is expected to return 3 values. For example: ```U, S, V = getSVD(cov_matrix)```\n",
    "- You can follow the skeleton below to have an idea on how the autograder's test calls your functions:\n",
    "```\n",
    "U, S, V = getSVD(cov_matrix)\n",
    "z = getKComponents(U, X, k)\n",
    "ratio = getVarianceRatio(z, U, X, k)\n",
    "```\n",
    "- Using the built-in PCA implementation in sklearn, the approximate X matrix can be obtained by function ```inverse_transform```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-3: SVD computation\n",
    "Now compute the SVD on the covariance matrix $SVD(\\Sigma)$. You may use the svd implementation in numpy.linalg.svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSVD(cov_matrix):\n",
    "    #TODO user np.linalg.svd here\n",
    "    u,s,v = np.linalg.svd(cov_matrix,full_matrices=False)\n",
    "    return u, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-4: Compute PCA matrix (K dimensional)\n",
    "Now select the first $k$ columns from the matrix $U$ and multiply with $X$ to get $k$ dimensional representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKComponents(U, X, K=2):\n",
    "    # implement matrix multiplication of first k columns of U * X\n",
    "    Z = np.dot(X, U[:,:K])    \n",
    "    U_reduced = U[:,:K]\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-5: Compute Reconstruction Error\n",
    "Implement a function to compute the variance ratio (from reconstruction error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVarianceRatio(Z, U, X, K):\n",
    "    U = U[:,:K]\n",
    "    X_approx_pca = np.dot(Z, np.transpose(U))\n",
    "    ratio = np.mean((X-X_approx_pca).T.dot(X-X_approx_pca))/np.mean(X.T.dot(X))\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the variance ration to the built-in PCA implementation in sklearn https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html (this step is optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtinPCA(X, K):\n",
    "    pca = PCA(n_components=K)\n",
    "    z_pca = pca.fit_transform(X)\n",
    "    X_approx_pca = pca.inverse_transform(z_pca)\n",
    "    ratio_pca = np.mean((X-X_approx_pca).T.dot(X-X_approx_pca))/np.mean(X.T.dot(X))\n",
    "    return ratio_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-6: Scatter plot 2-dimensional PCA\n",
    "Using matplotlib plot the 2-dimensional scatter plot of the first 2 compoenents with y (movie genre from movies.dat file) as labels. Remember you are plotting movies in dimensions so you can label them with movie generes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFunction(PCA, movie_data):\n",
    "    types = movie_data['mapped_genre'].unique()\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    movie_data = movie_data.head(3666)\n",
    "    for i in types:\n",
    "        ax.scatter(PCA[movie_data['mapped_genre']==i, 0], PCA[movie_data['mapped_genre']==i, 1], label = i, alpha=1, s = 8)\n",
    "    ax.legend(loc='upper left', fontsize='x-large')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_genre(x, types):\n",
    "    for t in types:\n",
    "        if t in x:\n",
    "            return t\n",
    "    return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-7 Find best $K$\n",
    "Find the minimum value of $K$ with which the ratio between averaged squared projection error with total variation in data is less than 0.1% in other words we retain 99.9% of the variance. You can achieve this by repeating getKComponents with $K=1$ until the variance ratio is <= 0.1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestK(initial, step, U, X):\n",
    "    #TODO use the getVarianceRatio to find the best K\n",
    "     for k in range(initial, 30, step):\n",
    "        Z = getKComponents(U, X, k)\n",
    "        U_reduced = U[: , :k]\n",
    "        ratio = getVarianceRatio(Z, U_reduced, X, k)\n",
    "        if ratio <= 0.0019:\n",
    "            break\n",
    "    \n",
    "     return k, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-8: TSNE visualization\n",
    "Finally, having found an optimal $K$ use these components as an input data to another dimensionality reduction method called tSNE (https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) and reduce it to 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, scatter plot the components given by the tSNE using matplotlib compare it to the earlier scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFunction(PCA, movie_data):\n",
    "    types = movie_data['mapped_genre'].unique()\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    movie_data = movie_data.head(3666)\n",
    "    for i in types:\n",
    "        ax.scatter(PCA[movie_data['mapped_genre']==i, 0], PCA[movie_data['mapped_genre']==i, 1], label = i, alpha=1, s = 3)\n",
    "    ax.legend(loc='upper left', fontsize='x-large')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-9: Recommender System\n",
    "## Part-9a\n",
    "    - In this part you will use the SVD to build your own recommender engine for the movielens data\n",
    "    - Use the user-movie rating matrix from the training data (data/train.csv) to decmopose it into USV^T or use getSVD function from earlier\n",
    "    - Convert the S to the diagonal matrix using np.diag\n",
    "    - Take k best components (extract kxk matrix). k value can be using PCA k_min you found earlier\n",
    "    - Take square root of S matrix using scipy.sqrtm package as s_squre_root\n",
    "    - Multiply take U_reduced (first k columns of U) with s_squre_root (nxk . kxk)\n",
    "    - Then multiply the result from previous step with V_reduced which is a kxm matrix and return a recommendation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendationMatrix(U, S, V, k):\n",
    "    S = np.diag(S)\n",
    "    S = S[0:k, 0:k]\n",
    "    U = U[ : , 0:k]\n",
    "    V = V[0:k,  : ]\n",
    "    S_root_value=sqrtm(S)\n",
    "    USk=np.dot(U,S_root_value)\n",
    "    USkV = np.dot(USk, V)\n",
    "    return USkV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-9a\n",
    "    - Use the recommendation matrix from getRecommendationMatrix to recommend movies for the user-movie pairs in data/test.csv\n",
    "    - If user-movie pair exits in the training data, use the matrix value as the recommended rating, else take the mean of the ratings for that movie and recommend that\n",
    "    - Write the recommended ratings in submissions.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovieRecommendations():\n",
    "    # Use user-movie rating matrix X from readMovieRatingData() earlier to compute SVD\n",
    "    # Read data/test.csv in a similar way and get the test dataframe\n",
    "    test_data = pd.read_csv('data/test.csv')\n",
    "    XX = readMovieRatingData().to_numpy()\n",
    "    ratingdata_matrix = pd.read_csv('data/train.csv')\n",
    "    ratings_matrix_pv = ratingdata_matrix.pivot(index = 'user_id', columns = 'movie_id', values = 'rating')\n",
    "    movie_id_list_data = ratingdata_matrix['movie_id'].unique()\n",
    "    movie_id_list_data.sort()\n",
    "    movie_id_list_data = list(movie_id_list_data)\n",
    "    ratings_matrix_pvtdf = pd.DataFrame(ratings_matrix_pv)        \n",
    "    for i in ratings_matrix_pvtdf.columns[ratings_matrix_pvtdf.isnull().any(axis=0)]:\n",
    "        ratings_matrix_pvtdf[i].fillna(ratings_matrix_pvtdf[i].mean(),inplace=True)\n",
    "    ratings_matrix_average_value = ratings_matrix_pvtdf.to_numpy()    \n",
    "    U, S, V  = np.linalg.svd(XX)\n",
    "    USkV = getRecommendationMatrix(U,S,V,200)\n",
    "    USV = USkV + ratings_matrix_average_value        \n",
    "    pred = []    \n",
    "    for _,row in test_data.iterrows():\n",
    "        user_id_data = row['user_id']\n",
    "        movie_id_data = row['movie_id']\n",
    "        if movie_id_data in movie_id_list_data:\n",
    "            movie_id_index = movie_id_list_data.index(movie_id_data)\n",
    "            pred.append(USV[user_id_data-1][movie_id_index])\n",
    "        else:\n",
    "            pred.append(0)\n",
    "                \n",
    "    sumissions_df = test_data.copy()\n",
    "    sumissions_df['rating'] = pred\n",
    "    sumissions_df.to_csv('submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPCA():\n",
    "    #TODO add all PCA related steps here to avoid running it when this file is used as a package\n",
    "    X = readMovieRatingData().T\n",
    "    cov_matrix = np.cov(X.T, bias=False)\n",
    "    U, S, V = getSVD(cov_matrix)\n",
    "    X = X.to_numpy()\n",
    "    Z = getKComponents(U, X, 200)\n",
    "    U_reduced = U[: , :200]\n",
    "    ratio = getVarianceRatio(Z, U_reduced, X, 200)\n",
    "    best_k, best_ratio = findBestK(10, 1, U, X)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    getMovieRecommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
